<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Raul E. Lopez Briega">
<meta name="description" content="Libro online de la comunidad de Inteligencia Artificial Argentina IAAR - Visión por computadora. ¿Qué es la visión por computadora?. Aplicaciones de la visión por computadora. Redes neuronales convolucionales. OpenCV. 
">
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Visión por computadora - Libro online de IAAR</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link rel="stylesheet" href="../css/social-share-kit.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Visi\u00f3n por computadora";
    var mkdocs_page_input_path = "vision-por-computadora.md";
    var mkdocs_page_url = "/vision-por-computadora/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script>
  <script type="text/javascript" src="../js/social-share-kit.min.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-29080434-5', 'iaarbook');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-book"> Libro online de IAAR</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar en libro" />
  </form>
</div>
      </div>
      <!-- Left & centered positioning -->
<div class="ssk-sticky ssk-right ssk-center ssk-lg ssk-sticky-hide-xs">
    <a href="" class="ssk ssk-facebook"></a>
    <a href="" class="ssk ssk-twitter"></a>
    <a href="" class="ssk ssk-linkedin"></a>
    <a href="" class="ssk ssk-google-plus"></a>
    <a href="" class="ssk ssk-email"></a>
</div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Introducción</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../inteligencia-artificial/">Inteligencia Artificial</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../deeplearning/">Deep Learning</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../machine-learning/">Machine Learning</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../datascience/">Ciencia de datos</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../bigdata/">Big Data</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../internet-de-las-cosas/">Internet de las cosas</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../procesamiento-del-lenguaje-natural/">Procesamiento de lenguaje</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">Visión por computadora</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#vision-por-computadora">Visión por Computadora</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#que-es-la-vision-por-computadora">¿Qué es la visión por computadora?</a></li>
        
            <li><a class="toctree-l3" href="#aplicaciones-de-vision-por-computadora">Aplicaciones de visión por computadora</a></li>
        
            <li><a class="toctree-l3" href="#redes-neuronales-convolucionales">Redes neuronales convolucionales</a></li>
        
            <li><a class="toctree-l3" href="#opencv">OpenCV</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../python/">Intro Python</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../rlang/">Intro R</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../bibliografia/">Bibliografía</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../glosario/">Glosario</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../recursos/">Recursos</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../sobre-iaar/">Sobre IAAR</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../autor/">Sobre el autor</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../contacto/">Contacto</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>
<a href="https://github.com/IAARhub/iaarbook" target="_blank"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"></a>
    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Libro online de IAAR</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Visión por computadora</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="vision-por-computadora">Visión por Computadora</h1>
<p><center><img src="https://iaarbook.github.io/img/computer-vision.jpg" title="Visión artificial" alt="Visión artificial" width="80%" height="80%"></center></p>
<p>De nuestros cinco sentidos, la <em>visión</em> es sin duda uno de los más importantes y uno de los que más dependemos. Hay quienes dicen incluso, que los ojos son una ventana hacia nuestro cerebro; ya que alrededor del 50 % de las áreas de nuestro cerebro se utilizan en funciones para procesar la gran cantidad de información que ingresa a través de nuestra vista.</p>
<p>En cierto sentido se podría decir que la <em>visión</em> es, en primer lugar, una tarea de procesamiento de información; pero a si mismo, es algo mucho más complejo, ya que para poder saber que es lo qué hay en el mundo nuestros cerebros deben ser capaces de <em>representar</em> esta información en toda su abundancia de color, forma, movimiento, detalle y belleza. El estudio de la <em>visión</em> debe entonces incluir, no solo el estudio de cómo extraer de las imágenes los diversos aspectos del mundo que nos son útiles, sino también una investigación sobre la naturaleza de las representaciones internas mediante las cuales captamos esta información y la utilizamos como base para las decisiones sobre nuestros pensamientos y acciones. Esta dualidad, de <em>representación</em> y <em>procesamiento de información</em> esta en el corazón de la mayoría de las tareas de procesamiento de la información y se profundizará más en el estudio de los problemas relacionados con la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a>. </p>
<h2 id="que-es-la-vision-por-computadora">¿Qué es la visión por computadora?</h2>
<p>Hoy en día, podemos encontrar imágenes y videos por todas partes. Los sitios para compartir videos y las redes sociales los tienen por billones. Prácticamente todos los teléfonos móviles y computadoras poseen cámaras incorporadas. Es muy común que las personas tengan varios giga-bytes de fotos y videos en sus dispositivos. Programar una computadora y diseñar los <a href="https://iaarbook.github.io/glosario/#Algoritmo">algoritmos</a> para entender qué hay en esas fotos y videos, es el campo de estudio de la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> o <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Computer vision</a>.</p>
<p>La <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> consiste en la extracción automatizada de información de las imágenes. Por información podemos entender casi cualquier cosa; desde modelos 3D, posición de la cámara, reconocimiento de objetos, y agrupación y búsqueda de contenido. También puede incluir la deformación de las imágenes, la eliminación de ruidos y la realidad aumentada. Muchas veces la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> trata de imitar a la visión humana, pero otras ves la geometría o un enfoque más estadístico puede ser fundamental para resolver un problema. La <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> contiene una mezcla de programación, modelado y matemática que lo convierte en un campo de estudio sumamente atractivo. </p>
<h2 id="aplicaciones-de-vision-por-computadora">Aplicaciones de visión por computadora</h2>
<p>La <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> es un área con más de 40 años de investigación, por lo que ya contamos con varias aplicaciones de las técnicas desarrolladas. Estas aplicaciones incluyen:</p>
<ul>
<li>
<p><strong><a href="https://es.wikipedia.org/wiki/Reconocimiento_%C3%B3ptico_de_caracteres">Reconocimiento óptico de caracteres (OCR)</a></strong>: Que consiste en la identificación automáticamente a partir de una imagen de símbolos o caracteres que pertenecen a un determinado alfabeto, para luego almacenarlos en forma de datos.</p>
</li>
<li>
<p><strong>Inspección robotizada</strong>: La inspección rápida de las piezas para garantizar la calidad de los componentes de fabricación utilizando una visión estéreo con iluminación especializada. </p>
</li>
<li>
<p><strong>Venta al por menor</strong>: Como ser los clásicos lectores de barras que encontramos en los supermercados para reconocer los precios de los productos en la línea de cajas. </p>
</li>
<li>
<p><strong>Construcción de modelos 3D</strong>: La construcción automatizada de modelos 3D a partir de fotografías. </p>
</li>
<li>
<p><strong>Imágenes médicas</strong>: Como ser la tecnología utilizada para tomar radiografías y las técnicas para detectar tumores malignos y anomalías en las mismas. </p>
</li>
<li>
<p><strong>Seguridad automotriz</strong>: Ayudando a detectar obstáculos mediante un sistema de conducción asistida utilizando diferentes cámaras.    </p>
</li>
<li>
<p><strong>Captura de movimiento</strong>: Utilizando marcadores retro-reflexivos vistos desde múltiples cámaras u otras técnicas para la captura de movimientos de los actores para utilizar en <a href="https://es.wikipedia.org/wiki/Animaci%C3%B3n_por_computadora">animación por computadora</a>.</p>
</li>
<li>
<p><strong>Vigilancia</strong>: Monitoreo de intrusos, análisis del tráfico vial, y monitoreo de piscinas para víctimas de ahogamiento. </p>
</li>
<li>
<p><strong>Reconocimiento de huellas dactilares y biometría</strong>: Para la identificación automática de accesos y también utilizada para aplicaciones forenses.</p>
</li>
<li>
<p><strong>Detección de caras</strong>: Utilizado para mejorar el foco de las cámaras y para hacer una búsqueda más relevante de personas en imágenes. </p>
</li>
</ul>
<p>Como estas, existen muchas más aplicaciones de las técnicas de <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a>; muchas de las cuales son algo ya común para nosotros, como la sugerencia para etiquetar de Facebook. </p>
<h2 id="redes-neuronales-convolucionales">Redes neuronales convolucionales</h2>
<p>Gracias a que el área del cerebro responsable de la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n">visión</a> es una de las zonas más estudiadas y que más conocemos; sabemos que la <a href="https://es.wikipedia.org/wiki/Corteza_visual">corteza visual</a> contiene una disposición jerárquica compleja de <a href="https://es.wikipedia.org/wiki/Neurona">neuronas</a>.  Por ejemplo, la información visual es introducida en la corteza a través del área visual primaria, llamada V1. Las <a href="https://es.wikipedia.org/wiki/Neurona">neuronas</a> de V1 se ocupan de características visuales de bajo nivel, tales como pequeños segmentos de contorno, componentes de pequeña escala del movimiento, <a href="https://es.wikipedia.org/wiki/Disparidad_binocular">disparidad binocular</a>, e información básica de contraste y color. V1 luego alimenta de información a otras áreas, como V2, V4 y V5. Cada una de estas áreas se ocupa de los aspectos más específicos o abstractas de la información. Por ejemplo, las <a href="https://es.wikipedia.org/wiki/Neurona">neuronas</a> en V4 se ocupan de objetos de mediana complejidad, tales como formas de estrellas en diferentes colores. La <a href="https://es.wikipedia.org/wiki/Corteza_visual">corteza visual</a> de los animales es el más potente sistema de procesamiento visual que conocemos, por lo que suena lógico inspirarse en ella para crear una variante de <a href="https://es.wikipedia.org/wiki/Red_neuronal_artificial">redes neuronales artificiales</a> que ayude a identificar imágenes; es así como surgen las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a>.</p>
<p>Las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> se componen de <a href="https://es.wikipedia.org/wiki/Neurona">neuronas</a> que tienen <em>pesos</em> y <em>sesgos</em> que pueden aprender. Cada <a href="https://es.wikipedia.org/wiki/Neurona">neurona</a> recibe algunas entradas, realiza un <a href="https://es.wikipedia.org/wiki/Producto_escalar">producto escalar</a> y luego aplica una función de activación. Lo que diferencia a las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> es que suponen explícitamente que las entradas son imágenes, lo que nos permite codificar ciertas propiedades en la arquitectura; permitiendo ganar en eficiencia y reducir la cantidad de parámetros en la red. Las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> trabajan modelando de forma consecutiva pequeñas piezas de información, y luego combinando esta información en las capas más profundas de la red. Una manera de entenderlas es que la primera capa intentará detectar los bordes y establecer patrones de detección de bordes. Luego, las capas posteriores trataran de combinarlos en formas más simples y, finalmente, en patrones de las diferentes posiciones de los objetos, iluminación, escalas, etc. Las capas finales intentarán hacer coincidir una imagen de entrada con todos los patrones y arribar a una predicción final como una suma ponderada de todos ellos. De esta forma las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> son capaces de modelar complejas variaciones y comportamientos dando predicciones bastantes precisas.</p>
<h3 id="estructura-de-las-redes-neuronales-convolucionales">Estructura de las Redes Neuronales Convolucionales</h3>
<p>En general, las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> van a estar construidas con una estructura que contendrá 3 tipos distintos de capas:</p>
<h4 id="capa-convolucional">Capa convolucional</h4>
<p>Esta es la capa que le nombre a la red, lo que distingue a las <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> de cualquier otra <a href="https://es.wikipedia.org/wiki/Red_neuronal_artificial">red neuronal</a> es utilizan un operación llamada <a href="https://es.wikipedia.org/wiki/Convoluci%C3%B3n">convolución</a> en alguna de sus capas; en lugar de utilizar la multiplicación de matrices que se aplica generalmente.
La operación de <a href="https://es.wikipedia.org/wiki/Convoluci%C3%B3n">convolución</a> recibe como <em>entrada o input</em> la imagen y luego aplica sobre ella un <em>filtro o kernel</em> que nos devuelve un <em>mapa de las características</em> de la imagen original, de esta forma logramos reducir el tamaño de los parámetros.
La <a href="https://es.wikipedia.org/wiki/Convoluci%C3%B3n">convolución</a> aprovecha tres ideas importantes que pueden ayudar a mejorar cualquier sistema de <a href="https://iaarbook.github.io/machine-learning/">Machine Learning</a>, ellas son: 
<em> <strong>interacciones dispersas</strong>, ya que al aplicar un filtro de menor tamaño sobre la entrada original podemos reducir drásticamente la cantidad de parámetros y cálculos;
</em> los <strong>parámetros compartidos</strong>, que hace referencia a compartir los parámetros entre los distintos tipos de filtros, ayudando también a mejorar la eficiencia del sistema; y las <strong>representaciones equivariante</strong>, que indican que si las entradas cambian, las salidas van a cambiar también en forma similar. </p>
<p>Por otra parte, la <a href="https://es.wikipedia.org/wiki/Convoluci%C3%B3n">convolución</a> proporciona un medio para trabajar con entradas de tamaño variable, lo que puede ser también muy conveniente.</p>
<p><img alt="Convolución" title="Convolución" src="http://relopezbriega.github.io/images/conv_layer.png"></p>
<h4 id="capa-de-reduccion-o-pooling">Capa de reducción o pooling</h4>
<p>La capa de reducción o <em>pooling</em> se coloca generalmente después de la capa <em>convolucional</em>. Su utilidad principal radica en la reducción de las dimensiones espaciales (ancho x alto) del volumen de entrada para la siguiente capa <em>convolucional</em>. No afecta a la dimensión de profundidad del volumen.
La operación realizada por esta capa también se llama <em>reducción de muestreo</em>, ya que la reducción de tamaño conduce también a la pérdida de información. Sin embargo, una pérdida de este tipo puede ser beneficioso para la red por dos razones:</p>
<ul>
<li>la disminución en el tamaño conduce a una menor sobrecarga de cálculo para las próximas capas de la red;</li>
<li>también trabaja para reducir el <a href="http://relopezbriega.github.io/blog/2016/05/29/machine-learning-con-python-sobreajuste/">sobreajuste</a>.</li>
</ul>
<p>La operación que se suele utilizar en esta capa es <em>max-pooling</em>, que divide a la imagen de entrada en un conjunto de rectángulos y, respecto de cada subregión, se va quedando con el máximo valor.</p>
<p><img alt="max pooling" title="max pooling" src="http://relopezbriega.github.io/images/Max_pooling.png"></p>
<h4 id="capa-clasificadora-totalmente-conectada">Capa clasificadora totalmente conectada</h4>
<p>Al final de las capas <em>convolucional</em> y de <em>pooling</em>, las redes utilizan generalmente capas completamente conectados en la que cada pixel se considera como una <a href="https://es.wikipedia.org/wiki/Neurona">neurona</a> separada al igual que en una <a href="https://es.wikipedia.org/wiki/Red_neuronal_artificial">red neuronal</a> regular. Esta última capa clasificadora tendrá tantas <a href="https://es.wikipedia.org/wiki/Neurona">neuronas</a> como el número de clases que se debe predecir.</p>
<p>Los modelos de <a href="https://iaarbook.github.io/deeplearning/">Deep Learning</a> basados en <a href="http://relopezbriega.github.io/blog/2016/08/02/redes-neuronales-convolucionales-con-tensorflow/">redes neuronales convolucionales</a> han logrado resultados sorprendentes en varios problemas de <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a>, como ser los casos de clasificación de imágenes y detección de objetos. </p>
<h2 id="opencv">OpenCV</h2>
<p><a href="http://opencv.org/">OpenCV</a> es una librería <a href="https://iaarbook.github.io/glosario/#OpenSource">Open Source</a> de <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> que nos permite manipular imágenes y videos para realizar una variedad de tareas que van desde la detección automática de caras, a la visualización de las imágenes de una cámara Web; o hasta enseñarle a un robot a reconocer objetos en la vida real. Fue creada en 1999, por Gary Bradski, quien trabajaba en <a href="https://www.intel.la/content/www/xl/es/homepage.html">Intel</a>, y que lanzó <a href="http://opencv.org/">OpenCV</a> con la intensión de acelerar la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> y la <a href="https://iaarbook.github.io/inteligencia-artificial/">Inteligencia Artificial</a> proporcionando una infraestructura sólida para todos los que trabajan en el campo. La librería está escrita en <a href="http://es.wikipedia.org/wiki/C_(lenguaje_de_programaci%C3%B3n)">C</a> y <a href="http://es.wikipedia.org/wiki/C%2B%2B">C++</a> y se puede ejecutar bajo <a href="https://www.linuxfoundation.org/">Linux</a>, Windows y Mac OS X. Posee un desarrollo activo de interfaces para <a href="https://iaarbook.github.io/python/">Python</a>, <a href="http://es.wikipedia.org/wiki/Java_(lenguaje_de_programaci%C3%B3n)">Java</a> , MATLAB y otros lenguajes, incluyendo el soporte para plataformas como <a href="https://www.android.com/">Android</a> e iOS para aplicaciones móviles. </p>
<p><a href="http://opencv.org/">OpenCV</a> contiene más de 500 funciones que abarcan muchas áreas de <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a>, incluyendo tales como: inspección de productos de fábrica, imágenes médicas, seguridad, interfaz de usuario, calibración de cámara, visión estéreo y robótica. Debido a que la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a> y el <a href="https://iaarbook.github.io/machine-learning/">Machine Learning</a> a menudo van de la mano, <a href="http://opencv.org/">OpenCV</a> también contiene una librería completa de uso general de <a href="https://iaarbook.github.io/machine-learning/">Machine Learning</a> (ML); la cual se centra en el reconocimiento de patrones estadísticos y el agrupamiento. <a href="http://opencv.org/">OpenCV</a> es sin dudas el lugar por dónde comenzar para empezar a incursionar en el mundo de la <a href="https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial">Visión por computadora</a>. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../python/" class="btn btn-neutral float-right" title="Intro Python">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../procesamiento-del-lenguaje-natural/" class="btn btn-neutral" title="Procesamiento de lenguaje"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Todo el material de este sitio esta bajo licencia <a href="http://creativecommons.org/licenses/by-nc/3.0/" onclick="__gaTracker('send', 'event', 'outbound-widget', 'http://creativecommons.org/licenses/by-nc/3.0/', 'Creative Commons Attribution-NonCommercial 3.0 Unported License');" target="_blank" rel="license" title="Licencia de este sitio">Creative Commons Attribution-NonCommercial 3.0 Unported License</a>
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../procesamiento-del-lenguaje-natural/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../python/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<script type="text/javascript">
init_mathjax = function() {
    if (window.MathJax) {
        // MathJax loaded
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            },
            displayAlign: 'left', // Change this to 'center' to center equations.
            "HTML-CSS": { linebreaks: { automatic: true } },
             SVG: { linebreaks: { automatic: true } }
        });
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    }
}
init_mathjax();
</script>
<script type="text/javascript">
  SocialShareKit.init();
  </script>

</body>
</html>
